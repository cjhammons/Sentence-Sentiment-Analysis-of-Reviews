{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Research Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import csv\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "\n",
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>So there is no way for me to plug it in here i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good case, Excellent value.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Great for the jawbone.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tied to charger for conversations lasting more...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The mic is great.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence label\n",
       "0  So there is no way for me to plug it in here i...     0\n",
       "1                        Good case, Excellent value.     1\n",
       "2                             Great for the jawbone.     1\n",
       "3  Tied to charger for conversations lasting more...     0\n",
       "4                                  The mic is great.     1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('data/amazon_cells_labelled.txt') as f:\n",
    "    reader = csv.reader(f, delimiter='\\t')\n",
    "    data = list(reader)\n",
    "\n",
    "amazon = pd.DataFrame(data, columns=['sentence', 'label'])\n",
    "\n",
    "amazon.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max length of sentence: 30\n",
      "Average length of sentence: 10.29\n"
     ]
    }
   ],
   "source": [
    "# Tokenize training and testdata\n",
    "tok = keras.preprocessing.text.Tokenizer()\n",
    "tok.fit_on_texts(amazon['sentence'])\n",
    "X_train = tok.texts_to_sequences(amazon['sentence'])\n",
    "X_val = tok.texts_to_sequences(amazon['sentence'])\n",
    "\n",
    "\" \".join(map(str,X_train[0]))\n",
    "\n",
    "# print lengths of the training and test sentences\n",
    "lengths = [len(i) for i in X_train+X_val]\n",
    "print(f'Max length of sentence: {max(lengths)}')\n",
    "print(f'Average length of sentence: {np.mean(lengths)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'here in the us unless i go by a converter'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pad sequences so each is the length of 10, the average\n",
    "X_train = keras.preprocessing.sequence.pad_sequences(X_train, padding='post', maxlen=10)\n",
    "X_val = keras.preprocessing.sequence.pad_sequences(X_val, padding='post', maxlen=10)\n",
    "\n",
    "reverse_word_map = dict(map(reversed, tok.word_index.items()))\n",
    "\n",
    "' '.join(reverse_word_map[i] for i in X_train[0] if i!=0) # exclude 0 due to padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aa1c0332c1f0569c3cc1190506c80fab67af9672c203985e98fb5c081c05f0ff"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('d213-2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
